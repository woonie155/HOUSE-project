{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "캡스톤4 학습 gpu코랩사용",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1mjqt3kCC-Yqj0AsDToJ1_EonxlS8-SWV",
      "authorship_tag": "ABX9TyPLN7un9Hz3mJZdm/gibOQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lena1005a/HOUSE-project/blob/main/%EC%BA%A1%EC%8A%A4%ED%86%A44_%ED%95%99%EC%8A%B5_gpu%EC%BD%94%EB%9E%A9%EC%82%AC%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCvBa_5PeAj4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy64ppqC3FGY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "\n",
        "gesture = ['ALT_TAB', 'ALT_F4', 'FULL', 'SOUND_CONTROL']\n",
        "\n",
        "data = np.concatenate([\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_TAB.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_F4.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_FULL.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_SOUND_CONTROL.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_TAB_ru.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_F4_ru.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_FULL_ru.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_SOUND_CONTROL_ru.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_TAB_rd.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_F4_rd.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_FULL_rd.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_SOUND_CONTROL_rd.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_TAB_lu.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_F4_lu.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_FULL_lu.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_SOUND_CONTROL_lu.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_TAB_ld.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_ALT_F4_ld.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_FULL_ld.npy'),\n",
        "    np.load('/gdrive/MyDrive/dataset/seq_SOUND_CONTROL_ld.npy'),\n",
        "], axis=0)\n",
        "\n",
        "x_data = data[:, :, :-1] \n",
        "labels = data[:, 0, -1]\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_data = to_categorical(labels, num_classes=len(gesture))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_data = x_data.astype(np.float32)\n",
        "y_data = y_data.astype(np.float32)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, shuffle=True, random_state=1)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, random_state=1)\n",
        "\n",
        "print(\"최종\")\n",
        "print(x_train.shape, y_train.shape) \n",
        "print(x_val.shape, y_val.shape)\n",
        "print(x_test.shape, y_test.shape) \n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(gesture), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100,\n",
        "    callbacks=[\n",
        "        ModelCheckpoint('models/cursor_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
        "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=20, verbose=1, mode='auto')\n",
        "    ]\n",
        ")\n",
        "\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('models/cursor_model.h5')\n",
        "y_pred = model.predict(x_test)\n",
        "test_p = multilabel_confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "\n",
        "for i in range(len(test_p)):\n",
        "    print(gesture[i],\"\\n\", test_p[i], \"\\n\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZbSun-hQlGQ"
      },
      "source": [
        "![image](https://user-images.githubusercontent.com/73781215/141732040-fe198dcd-a09e-4c78-9fd0-7991cdcea13e.png)\n"
      ]
    }
  ]
}